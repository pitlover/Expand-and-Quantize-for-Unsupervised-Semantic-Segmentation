save_dir: "output"
wandb:
  project: "Jigmentation"
  mode: "online"
  name: "HIHI_ema"
  notes: null

# ---------------------------------------------------------------- #
seed: 10
num_classes: 27
dataset_name: "cocostuff27"
data_dir: "../Datasets/cocostuff"

# ---------------------------------------------------------------- #
resume:
  checkpoint: null

# ---------------------------------------------------------------- #
model:
  pretrained:
    model_type: "vit_small"
    dino_patch_size: 8
    freeze_backbone: true
    drop_prob: 0.1
    pretrained_weights: null
  enc_num_blocks: 3
  dec_num_blocks: 3
  vq:
    vq_type: "ema"  # ema, param
    num_codebooks: [ 512, 512, 512 ]
    embed_dims: [ 128, 256, 384 ]
    beta: 0.25
    normalize: "z_trainable"  # l2, z_norm, z_trainable, none
    use_restart: false
    use_gumbel: true
    decay: 0.95
    eps: 1.0e-5

# ---------------------------------------------------------------- #
loss:
  recon_weight: 1.0
  vq_weight: 1.0

# ---------------------------------------------------------------- #
dataset:
  train:
    data_dir: ${data_dir}
    dataset_name: ${dataset_name}
    crop_type: "five"
    crop_ratio: 0.5
    loader_crop_type: "center"
    res: 224
  val:
    data_dir: ${data_dir}
    dataset_name: ${dataset_name}
    crop_type: null
    loader_crop_type: "center"  # none for voc
    res: 320

dataloader:
  train:
    batch_size: 64  # total
    num_workers: 4  # total
  val:
    batch_size: 32  # total
    num_workers: 2  # total

# ---------------------------------------------------------------- #
optimizer:
  model:
    name: "adamw"
    lr: 3.0e-4
    weight_decay: 1.0e-6
  cluster:
    name: "adam"
    lr: 3.0e-3
  linear:
    name: "adam"
    lr: 3.0e-3

# ---------------------------------------------------------------- #
scheduler:
  model:
    name: "constant"
  cluster:
    name: "constant"
  linear:
    name: "constant"

# ---------------------------------------------------------------- #
eval:
  output_type: "vq0"
  extra_classes: 0

# ---------------------------------------------------------------- #
train:
  max_epochs: 10
  print_interval_iters: 25
  valid_interval_iters: 100
  clip_grad: 1.0
  num_accum: 2