save_dir: "output"
wandb:
  project: "Jigmentation"
  mode: "online"
  name: "HIHI_large"
  notes: ""

# ---------------------------------------------------------------- #
seed: 10
num_classes: 27
dataset_name: "cocostuff27"
data_dir: "../Datasets/cocostuff"

# ---------------------------------------------------------------- #
resume:
  checkpoint: null
# ---------------------------------------------------------------- #
model:
  pretrained:
    model_type: "vit_small"
    dino_patch_size: 8
    freeze_backbone: true
    drop_prob: 0.1
    pretrained_weights: null
    dropout: false
  enc_num_blocks: 2
  dec_num_blocks: 4
  hidden_dim: 2048
  last_norm: false
  vq:
    vq_type: "ema"  # ema, param
    num_codebooks: [ 1024, 2048, 4096 ]
    embed_dims: [ 512, 512, 512 ]
    beta: 0.25
    normalize: "l2"  # l2, z_norm, z_trainable, none
    use_restart: false
    use_split: true
    use_gumbel: false
    decay: 0.99
    eps: 1.0e-5

# ---------------------------------------------------------------- #
loss:
  recon_weight: 1.0
  vq_weight: 100.0

# ---------------------------------------------------------------- #
dataset:
  train:
    data_dir: ${data_dir}
    dataset_name: ${dataset_name}
    crop_type: "five"
    crop_ratio: 0.5
    loader_crop_type: "center"
    res: 224
  val:
    data_dir: ${data_dir}
    dataset_name: ${dataset_name}
    crop_type: null
    loader_crop_type: "center"  # none for voc
    res: 320

dataloader:
  train:
    batch_size: 112  # total
    num_workers: 8  # total
  val:
    batch_size: 32  # total
    num_workers: 8  # total

# ---------------------------------------------------------------- #
optimizer:
  model:
    name: "adamw"
    lr: 3.0e-4
    weight_decay: 1.0e-6
  cluster:
    name: "adam"
    lr: 3.0e-3
  linear:
    name: "adam"
    lr: 3.0e-3

# ---------------------------------------------------------------- #
scheduler:
  model:
    name: "cos"
  cluster:
    name: "cos"
  linear:
    name: "cos"

# ---------------------------------------------------------------- #
eval:
  output_type: "vq0" # feat, vq0
  extra_classes: 0

# ---------------------------------------------------------------- #
train:
  max_epochs: 100
  print_interval_iters: 25
  valid_interval_iters: 100
  clip_grad: 1.0
  num_accum: 1